Task 1. Loading Data with Multi-Processing

- Need to use multiprocessing library that can spin up multiple processes in parallel to load the data
- Had read about it earlier after looking at the job description so had some idea
- The file on disk can be read in chunks lazily
- A pool of processes based on the cpu count can process (conversion to tensors) these chunks
- The obtained results can then be combined together
- The chunk size is made as an optional parameter to ensure flexibility
- Other approach could be to read the entire csv file without chunksize and then create chunks (as a list) ourselves following which it can be processed using pool of workers
- Also tested modin and polars to notice that polars almost always is faster compared to a single thread loader
- Tried to understand modin and polars implementations but took quite some time
- Knew about chunksize in pandas just went through the documentation again for syntax and confirmations
- Skimmed through a few blogs and documentation of multiprocessing

---

Task 2. Neural Network Implementation

- Revised how backpropagation works and wrote a few formulas (with chain rule) on paper to get comfortable
- Went through a couple of youtube videos and articles for this revision
- Struggled to do the matrix multiplication and tried understing einsum instead of transpose and matmul
- Used AI for understanding einsum and spent more time understanding gradient calculations
- Had backpropagation in bachelor's with manual calculations on paper, hence was comfortable doing on paper to avoid confusions

---

Task 3. Evaluating the Neural Network Output Bounds


