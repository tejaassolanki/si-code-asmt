Task 1. Loading Data with Multi-Processing

- Need to use multiprocessing library that can spin up multiple processes in parallel to load the data
- Had read about it earlier after looking at the job description so had some idea
- The file on disk can be read in chunks lazily
- A pool of processes based on the cpu count can process (conversion to tensors) these chunks
- The obtained results can then be combined together
- The chunk size is made as an optional parameter to ensure flexibility
- Other approach could be to read the entire csv file without chunksize and then create chunks (as a list) ourselves following which it can be processed using pool of workers
- Also tested modin and polars to notice that polars almost always is faster compared to a single thread loader
- Tried to understand modin and polars implementations but took quite some time
- Knew about chunksize in pandas just went through the documentation again for syntax and confirmations
- Skimmed through a few blogs and documentation of multiprocessing
- In terms of testing, unit tests with pytest could have been written to ensure proper working of individual method(s). Different sorts of data (can be mocked) as edge cases could be used to verify the working.
- Integration tests (to check for integrations) and performance testing (compare load times with single thread) can also be carried out.

---

Task 2. Neural Network Implementation

- Revised how backpropagation works and wrote a few formulas (with chain rule) on paper to get comfortable
- Went through a couple of youtube videos and articles for this revision
- Struggled to do the matrix multiplication and tried understing einsum instead of transpose and matmul
- Used AI for understanding einsum and spent more time understanding gradient calculations
- Had backpropagation in bachelor's with manual calculations on paper, hence was comfortable doing on paper to avoid confusions
- Unit tests with pytest can be written with a set of inputs and its corresponding outputs that can be asserted

---

Task 3. Evaluating the Neural Network Output Bounds

- The input tensor should be sliced to get the lower bounds and upper bounds separately
- Compute the lower and upper bounds and then combine into a single tensor
- The solution proposed by me seems way too easy which I am in doubt whether I have understood the problem
- The solution more or less I believe should consider +ve and -ve values to calculate upper and lower bounds
- Also, the proposed solution uses torch.einsum() which is similar to einops.einsum(). Uniformity should be preserved on which one to use as the latter is used for task 2.
- Similar to task 2, a fixed set of inputs (can include extreme cases) and its corresponding outputs can be asserted with unit tests
